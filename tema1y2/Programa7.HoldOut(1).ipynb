{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acasa\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Carga de datos\n",
    "iris = datasets.load_iris()\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de datos: 150 instancias y 4 atributos\n",
      "Valores de la clase: {0, 1, 2}\n",
      "[0 1 2] [50 50 50]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar características de la tabla de datos.\n",
    "print(\"Tabla de datos: %d instancias y %d atributos\" % (iris.data.shape[0], iris.data.shape[1]))\n",
    "print(\"Valores de la clase:\", set(iris.target))\n",
    "\n",
    "# Cuantificamos el número de instancias que contiene el dataset por clase\n",
    "valores, ocurrencias = np.unique(iris.target, return_counts=True)\n",
    "print(valores, ocurrencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  clases: [0 1 2]  ocurrencias:  [10  9 11]\n"
     ]
    }
   ],
   "source": [
    "# Test: hold-out split 80-20%. # Partición externa\n",
    "X_training, X_test, y_training, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "valores_test, ocur_test = np.unique(y_test, return_counts=True)\n",
    "print('Test: ', 'clases:', valores_test, ' ocurrencias: ', ocur_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar las características de entrenamiento y de test\n",
    "standardizer = StandardScaler()\n",
    "X_training = standardizer.fit_transform(X_training)\n",
    "X_test = standardizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento:   clases: [0 1 2]   ocurrencias: [32 30 34]\n",
      "Validation:      clases: [0 1 2]   ocurrencias: [ 8 11  5]\n"
     ]
    }
   ],
   "source": [
    "# Validación: hold-out split 80-20%. # Partición interna\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_training, y_training, test_size=0.2, random_state=42)\n",
    "valores_train, ocur_train = np.unique(y_train, return_counts=True)\n",
    "print('Entrenamiento: ', ' clases:', valores_train, '  ocurrencias:', ocur_train)\n",
    "\n",
    "valores_val, ocur_val = np.unique(y_val, return_counts=True)\n",
    "print('Validation:    ', ' clases:', valores_val, '  ocurrencias:', ocur_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción del objeto que contiene el algoritmo de aprendizaje.\n",
    "clf = DummyClassifier(strategy='prior', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del algoritmo de aprendizaje.\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en validación:  0.20833333333333334\n",
      "Exactitud en test:  0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del algoritmo de aprendizaje con el método \"score\" que devuelve directamente la métrica de 'accuracy'\n",
    "val_accuracy = clf.score(X_val, y_val)\n",
    "print(\"Exactitud en validación: \", val_accuracy)\n",
    "\n",
    "test_accuracy = clf.score(X_test, y_test)\n",
    "print(\"Exactitud en test: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones de validación  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Etiquetas reales validación [1 1 0 0 0 2 1 2 2 2 1 1 1 1 1 0 2 0 1 0 1 1 0 0]\n",
      "\n",
      "Predicciones de test  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Etiquetas reales test [1 1 0 0 0 2 1 2 2 2 1 1 1 1 1 0 2 0 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las predicciones sobre conjunto de validación y de test\n",
    "y_pred_val = clf.predict(X_val)\n",
    "print('Predicciones de validación ', y_pred_val)\n",
    "print('Etiquetas reales validación', y_val)\n",
    "\n",
    "y_pred_test = clf.predict(X_test)\n",
    "print('\\nPredicciones de test ', y_pred_val)\n",
    "print('Etiquetas reales test', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos un ejemplo con un clasificador más complejo que el \"dummyclassifier\"\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Definimos algoritmo\n",
    "clf = SVC(C=0.1, gamma='scale', kernel='rbf')\n",
    "\n",
    "# Entrenamos modelo\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculamos la accuracy y volvemos a parametrizar para mejorar los resultados \n",
    "val_accuracy = clf.score(X_val, y_val)\n",
    "\n",
    "print(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la accuracy en test utilizando el mejor de los modelos anteriores\n",
    "test_accuracy = clf.score(X_test, y_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo\n",
    "import pickle\n",
    "with open('../models/model.pickle', 'wb') as fw:\n",
    "    pickle.dump(clf, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo\n",
    "with open('../models/model.pickle', 'rb') as fr:\n",
    "    cfl2 = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 1 0 2 2 2 2 2 0 0]\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_predic = cfl2.predict(X_test)\n",
    "print(y_predic)\n",
    "print(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a65927f5967699fcd722c82a9c185cfa0040c4b95e3af20a6eefdab7483f21b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
